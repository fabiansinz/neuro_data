{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dynamic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make lists of keys needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['21067-8-9', '22285-2-10', '22279-5-15', '22620-14-9', '22667-2-13']\n",
    "\n",
    "keys = []\n",
    "for d in datasets:\n",
    "    animal, session, scan = d.split('-')\n",
    "    keys.append({\n",
    "     'animal_id': animal,\n",
    "     'session': session,\n",
    "     'scan_idx': scan,\n",
    "     'preproc_id': 0\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I demonstrate how to fill tables necessary for dynamic dataset generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_data.movies import data_schemas, configs, stats\n",
    "\n",
    "from neuro_data.movies.data_schemas import *\n",
    "meso = dj.create_virtual_module('meso', 'pipeline_meso')\n",
    "import datajoint as dj\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, make sure to insert your desired sessions into `MovieScanCandidate` table. Best would be to fill the `keys` list of dict like above and use the following line to insert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.MovieScanCandidate().insert(fuse.ScanDone & keys, ignore_extra_fields=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that your desired candidates are actually inserted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simply execute the tables below **in the following order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.MovieScan.populate(keys, display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.ConditionTier.populate(keys, display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.MovieClips.populate(keys, display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.InputResponse.populate(keys, display_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.Eye.populate(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.Eye2.populate(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schemas.Treadmill.populate(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomy.AreaMembership() & keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomy.LayerMembership() & keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know that they are from same area/layer, then you can use the following to manually fill the area and layer memberhsip table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = (meso.ScanSet.Unit & keys).fetch('KEY')\n",
    "\n",
    "for u in units:\n",
    "    u['brain_area'] = 'V1'\n",
    "    u['layer'] = 'L2/3'\n",
    "\n",
    "anatomy.AreaMembership.insert(units, ignore_extra_fields=True, allow_direct_insert=True, skip_duplicates=True)\n",
    "\n",
    "anatomy.LayerMembership.insert(units, ignore_extra_fields=True, allow_direct_insert=True, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To generate new entry into MovieMultiDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following specifying the key, one at a time. **CAUTION**: it can also create a group with more than one key in it at a time, so carefully read the prompt! Please also be sure to give a meaningful description of the data group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register each key entry separtely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    name = '{animal_id}-{session}-{scan_idx}'.format(**key)\n",
    "    MovieMultiDataset().add_entry(name, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the generation of HDF5 files, run the following, but only upon ensuring that you have all above tables filled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    key['preproc_id'] = 0\n",
    "    #print('Generating HDF5 file for {}'.format(key))\n",
    "    filename = data_schemas.InputResponse().get_filename(key)\n",
    "    #print('Data for {} can be found in {}'.format(key, filename))\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill out the Oracle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hash = dict(data_hash = \"ecb7c24fafd19503a2eef756ac4a24a4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.DataConfig.AreaLayer & data_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.Oracle.populate(MovieMultiDataset.Member & keys, data_hash)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
